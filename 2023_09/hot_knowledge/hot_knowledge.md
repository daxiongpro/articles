# **热点知识**

## **知识蒸馏与迁移学习**

SE-SSD：教师学生模型——自蒸馏，自己蒸馏自己。自己蒸自己为什么会更好呢？自己为什么能学习自己从而超过自己先前学习的成绩呢？这主要将其归结为“增益信息”的功劳，同传统蒸馏类似，自蒸馏中也可以通过一定的方式提供增益信息，使得蒸馏时能够学习到原始信息不包含的信息，因此得到收益。

知识蒸馏一般是在同一数据集上，将一个网络的中的知识转移到另一个网络中，二个网络的结构既可以相同也可以不同，最后让轻量化网络的结果接近于复杂网络的性能。同时在网络知识迁移的过程中，可以将多个网络学到的知识转移到一个网络中，使轻量化网络具有emsemble的结果。

迁移学习一般在不同的数据集上，可以在数据集有关联的任务中，选择更大的数据集进行模型的预训练，使模型具备出色的泛化能力。再将学到的参数迁移到目标数据集下进行辅助训练，使得模型可以不使用随机初始化来获得更快的网络收敛，同时也能从预训练模型中获得相关的参数。迁移学习的二个网络之间通常具有相同的主体网络结构。

> 参考：[自蒸馏：一种简单高效的优化方式](https://developer.aliyun.com/article/791081)

## 大模型

一般来说，我们认为参数量过亿的模型都可以称之为“大模型”。而在自动驾驶领域，大模型主要有两种含义：一种是参数量过亿的模型；另一种是由多个小模型叠加在一起组成的模型，虽然参数量不过亿，但也被称为“大模型”。

按照这样的定义，在自动驾驶领域，大模型已经开始被广泛运用了。在云端，我们可以发挥模型参数量增加带来的容量优势，用大模型完成一些数据挖掘、数据标注等任务。在车端，我们可以把分管不同子任务的多个小模型合并成一个“大模型”，这样可以节省车端计算环节的推理时间，增加安全性。

> 参考：[自动驾驶大模型](https://zhuanlan.zhihu.com/p/633105543)

## 日期

* 2023/09：知识蒸馏、大模型
